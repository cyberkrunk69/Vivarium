[
  {
    "task": "INTEGRATION: Wire up prompt_optimizer to grind_spawner\n\nThe prompt_optimizer.py exists but isn't being used. Integrate it:\n\n1. Read grind_spawner.py - find where GRIND_PROMPT_TEMPLATE is used\n2. Before creating the prompt, call:\n   - demos = collect_demonstrations(LOGS_DIR)\n   - relevant = get_relevant_demonstrations(task, demos)\n   - enhanced_prompt = optimize_prompt(base_prompt, relevant)\n\n3. Use the enhanced prompt instead of raw template\n4. Log when demonstrations are injected: '[Session N] Injected M demonstrations'\n\nThis implements DSPy's key insight: learning from successful runs.\n\nAppend integration lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "INTEGRATION: Wire up skill_registry to grind_spawner\n\nThe skill_registry.py exists but isn't being used. Integrate it:\n\n1. Read grind_spawner.py - find where the prompt is built\n2. Before execution, call:\n   - skill = retrieve_skill(task_description)\n   - if skill: inject skill code into prompt context\n\n3. Add to prompt: 'RELEVANT SKILL: {skill_name}\\n{skill_code}'\n4. Log when skills are retrieved: '[Session N] Retrieved skill: {name}'\n\nThis implements Voyager's key insight: compositional skill reuse.\n\nAppend skill integration lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "INTEGRATION: Wire up message_pool for worker coordination\n\nIf message_pool.py exists, integrate it. If not, create it:\n\n1. Create message_pool.py with:\n   - publish(from_role, msg_type, content)\n   - subscribe(role) -> list of relevant messages\n   - File-based JSON storage in message_pool.json\n\n2. Update grind_spawner.py to publish completion messages:\n   - On task complete: publish('worker', 'TASK_COMPLETE', result_summary)\n   - Include: task_id, files_modified, success status\n\n3. Future workers can subscribe and see what others completed\n\nThis implements MetaGPT's shared message pool pattern.\n\nAppend message pool lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "QUALITY: Add self-verification to grind completions\n\nFrom Voyager paper - add self-verification step:\n\n1. After grind session completes, before logging success:\n2. Check if task was actually completed:\n   - Parse the result output\n   - Look for 'Done', 'Complete', 'Success' indicators\n   - Check if any files were actually modified\n\n3. If verification fails, mark as partial completion\n4. Log verification results: '[Session N] Self-verification: PASS/FAIL'\n\nThis prevents false positives in success logging.\n\nAppend self-verification lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "QUALITY: Add error categorization to grind failures\n\nFrom Reflexion paper - categorize failures for better learning:\n\n1. When a grind session fails, categorize the error:\n   - TIMEOUT: Session exceeded time limit\n   - ENCODING: Unicode/charset issues\n   - IMPORT: Missing module errors\n   - SYNTAX: Python syntax errors\n   - RUNTIME: Execution errors\n   - UNKNOWN: Uncategorized\n\n2. Store category in grind log: 'error_category': 'TIMEOUT'\n3. Update learned_lessons.json with failure patterns\n4. Count errors by category for reporting\n\nThis enables targeted improvements based on failure types.\n\nAppend error categorization lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "DASHBOARD: Add failure tracking to PROGRESS.md\n\nEnhance PROGRESS.md with failure tracking:\n\n1. Read grind_logs/*.json and count:\n   - Total sessions\n   - Successful completions (returncode=0)\n   - Failures by category\n   - Average session duration\n\n2. Add new section to PROGRESS.md:\n   ## Health Metrics\n   - Success rate: X%\n   - Avg duration: Xs\n   - Common failures: [list]\n\n3. Update PROGRESS.md with these stats\n\nThis gives visibility into swarm health.\n\nAppend dashboard enhancement lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  }
]
