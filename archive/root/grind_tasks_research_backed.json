[
  {
    "task": "REFLEXION IMPLEMENTATION: Upgrade learned_lessons.json to episodic memory\n\nBased on arXiv:2303.11366 (Reflexion), our current learned_lessons.json is missing key components:\n\n1. Read current learned_lessons.json structure\n2. Add these fields to each lesson (per Reflexion paper):\n   - 'trial_number': Which attempt this insight came from\n   - 'task_feedback': The actual error/output that triggered the reflection  \n   - 'self_verification': Did applying this lesson work in subsequent trials?\n   - 'retrieval_cues': Keywords for when to retrieve this lesson\n\n3. Create utils/reflection.py with:\n   - add_reflection(task_id, feedback_signal, verbal_reflection, verification_result)\n   - retrieve_relevant_lessons(task_description) -> list of lessons with matching retrieval_cues\n   - synthesize_lessons(lessons) -> condensed prompt injection\n\nThe key insight from Reflexion: 'signal is amplified to natural language experience summaries which can be stored in long-term memory'\n\nAppend implementation lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "VOYAGER SKILL LIBRARY: Create executable skill library from learned_lessons\n\nBased on arXiv:2305.16291 (Voyager), we need an 'ever-growing skill library of executable code':\n\n1. Create skills/ directory\n2. Each skill is a small Python function that encapsulates a learned pattern\n3. Create skills/skill_registry.py:\n   - register_skill(name, code, description, preconditions, postconditions)\n   - retrieve_skill(task_description) -> matching skill code\n   - compose_skills(skill_list) -> combined executable\n\n4. Extract existing patterns from learned_lessons.json into skills:\n   - skill: 'import_config_constants' (from config_integration_lessons)\n   - skill: 'migrate_to_utils' (from utils_migration_lessons)\n   - skill: 'add_test_coverage' (from testing_and_refactoring_lessons)\n\nVoyager key insight: 'skills are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly'\n\nAppend lessons about skill library patterns to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "METAGPT SOP: Create Standardized Operating Procedures for grind tasks\n\nBased on arXiv:2308.00352 (MetaGPT), we need 'SOPs encoded into prompt sequences':\n\n1. Create sops/ directory with JSON procedure definitions\n2. Create sops/refactor.json:\n   {\n     \"name\": \"refactor_module\",\n     \"steps\": [\n       {\"action\": \"read_target_file\", \"output\": \"original_code\"},\n       {\"action\": \"identify_patterns\", \"input\": \"original_code\", \"output\": \"patterns\"},\n       {\"action\": \"check_existing_utils\", \"output\": \"available_utils\"},\n       {\"action\": \"plan_migration\", \"input\": [\"patterns\", \"available_utils\"], \"output\": \"migration_plan\"},\n       {\"action\": \"execute_migration\", \"input\": \"migration_plan\"},\n       {\"action\": \"verify_no_regressions\", \"output\": \"test_results\"},\n       {\"action\": \"document_lessons\", \"input\": \"test_results\"}\n     ],\n     \"quality_gates\": [\"tests_pass\", \"no_new_warnings\", \"lesson_documented\"]\n   }\n\n3. Create sop_executor.py that takes an SOP and executes it step-by-step\n\nMetaGPT key insight: 'agents with human-like domain expertise verify intermediate results and reduce errors'\n\nAppend lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "DSPy PROMPT OPTIMIZATION: Self-bootstrap our grind prompts\n\nBased on arXiv:2310.03714 (DSPy), we can achieve '25-65% improvement over standard few-shot prompting':\n\n1. Read current GRIND_PROMPT_TEMPLATE in grind_spawner.py\n2. Create prompt_optimizer.py with:\n   - collect_demonstrations(): Extract successful task completions from grind_logs/\n   - score_prompt(prompt_template, demonstrations) -> effectiveness score\n   - optimize_prompt(template, demonstrations) -> improved template\n\n3. Implement DSPy's key technique:\n   - Parse grind_logs/*.json for successful completions\n   - Extract the task description and actual steps taken\n   - Create few-shot examples from successful runs\n   - Inject 2-3 best examples into GRIND_PROMPT_TEMPLATE\n\n4. Add to grind_spawner.py:\n   - Before each grind, call get_relevant_demonstrations(task)\n   - Inject demonstrations into prompt\n\nDSPy key insight: 'modules learn by creating and collecting demonstrations'\n\nAppend prompt optimization lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "GENERATIVE AGENTS MEMORY: Implement reflection synthesis for learned_lessons\n\nBased on arXiv:2304.03442 (Generative Agents), we need to 'synthesize memories over time into higher-level reflections':\n\n1. Create memory_synthesis.py:\n   - load_all_lessons() -> flat list of all lessons from learned_lessons.json\n   - compute_importance(lesson) -> score based on frequency of retrieval, recency, impact\n   - generate_reflection(lessons_batch) -> higher-level insight from multiple lessons\n   - prune_redundant(lessons) -> remove lessons subsumed by reflections\n\n2. Implement the reflection hierarchy:\n   - Level 0: Raw observations (current lessons)\n   - Level 1: Patterns (lessons that appear 3+ times get synthesized)\n   - Level 2: Principles (patterns that span multiple categories)\n\n3. Add periodic synthesis:\n   - After every 10 grind sessions, run synthesis\n   - Promote frequently-retrieved lessons to higher levels\n   - Archive rarely-used lessons\n\nGenerative Agents key insight: 'retrieve them dynamically to plan behavior'\n\nAppend memory synthesis lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  },
  {
    "task": "CAMEL ROLE-PLAYING: Implement role-based task decomposition\n\nBased on arXiv:2303.17760 (CAMEL), implement 'inception prompting for autonomous cooperation':\n\n1. Create roles.py with role definitions:\n   - PLANNER: Breaks task into subtasks, assigns to specialists\n   - CODER: Writes implementation code\n   - REVIEWER: Validates code against requirements\n   - DOCUMENTER: Updates learned_lessons.json\n\n2. Each role has:\n   - system_prompt: Role-specific instructions\n   - allowed_tools: What the role can do\n   - handoff_conditions: When to pass to next role\n\n3. Modify grind_spawner.py to use roles:\n   - Complex tasks get decomposed by PLANNER first\n   - Simple tasks go directly to CODER\n   - All completions pass through REVIEWER before finishing\n\n4. Implement role-aware prompt injection:\n   - 'You are the {ROLE}. Your job is to {ROLE_DESCRIPTION}.'\n   - 'The PLANNER has assigned you: {SUBTASK}'\n   - 'When done, hand off to {NEXT_ROLE} with: {HANDOFF_FORMAT}'\n\nCAMEL key insight: 'role-playing can generate conversational data for studying behaviors'\n\nAppend role decomposition lessons to learned_lessons.json.",
    "budget": 2.00,
    "model": "haiku"
  }
]
